{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f191857-1312-4cd0-a912-d96c92463b72",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "167d6f37-3273-4f0d-a1b4-92b63dae18e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymongo\n",
      "  Downloading pymongo-4.4.0-cp39-cp39-macosx_10_9_universal2.whl (512 kB)\n",
      "\u001b[K     |████████████████████████████████| 512 kB 2.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting dnspython<3.0.0,>=1.16.0\n",
      "  Downloading dnspython-2.3.0-py3-none-any.whl (283 kB)\n",
      "\u001b[K     |████████████████████████████████| 283 kB 10.5 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: dnspython, pymongo\n",
      "Successfully installed dnspython-2.3.0 pymongo-4.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pymongo\n",
    "from pymongo import MongoClient\n",
    "from datetime import datetime\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b954d84b-4950-4cd8-a435-e08404262d21",
   "metadata": {},
   "source": [
    "# Create client connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2824ecbd-31c6-4c28-b3ab-705f65e0239a",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient('mongodb://127.0.0.1:27017/')\n",
    "db = client.get_database(\"test\")\n",
    "collection = db.get_collection(\"smart-meter-benchmark\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c3d5ae-642d-4b05-9901-43823e6f430c",
   "metadata": {},
   "source": [
    "# Simple Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1cf7d5f-7eea-46b4-954a-fda8a75d67d7",
   "metadata": {},
   "source": [
    "## First Query Workload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "98e82576-ee3f-456d-afcc-fd096105cf6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "energy_min: 0.064, energy_max: 0.312\n",
      "energy_min: 0.065, energy_max: 0.299\n",
      "energy_min: 0.064, energy_max: 0.7829999999999999\n",
      "energy_min: 0.066, energy_max: 1.1619999\n",
      "energy_min: 0.065, energy_max: 0.742\n",
      "Query execution time: 0.32806396484375 milliseconds\n"
     ]
    }
   ],
   "source": [
    "# Convert to datetime\n",
    "start = datetime(2012, 6, 1)\n",
    "end = datetime(2013, 6, 1)\n",
    "\n",
    "# Specify query\n",
    "query = {\n",
    "    \"LCLid\": \"MAC000131\",\n",
    "    \"day\": {'$lt': end, '$gte': start}\n",
    "}\n",
    "\n",
    "# Start timer\n",
    "start_time = time.time()\n",
    "\n",
    "# Retrieve all documents\n",
    "result_cursor = collection.find(query, {\"energy_min\": 1, \"energy_max\": 1})\n",
    "\n",
    "# End timer\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate execution time\n",
    "execution_time = (end_time - start_time)*1000\n",
    "\n",
    "# Print values\n",
    "count = 0\n",
    "for document in result_cursor:\n",
    "    energy_min = document.get(\"energy_min\")\n",
    "    energy_max = document.get(\"energy_max\")\n",
    "    print(f\"energy_min: {energy_min}, energy_max: {energy_max}\")\n",
    "    count += 1\n",
    "    if count == 5:\n",
    "        break\n",
    "    \n",
    "# Print execution time\n",
    "print(f\"Query execution time: {execution_time} milliseconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a686292-542e-4960-91c4-8f6cf934df93",
   "metadata": {},
   "source": [
    "## Second Query Workload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "aec92d1c-3437-40a8-a9ae-b6887375de26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "energy_min: 0.064, energy_max: 0.312\n",
      "energy_min: 0.065, energy_max: 0.299\n",
      "energy_min: 0.064, energy_max: 0.7829999999999999\n",
      "energy_min: 0.066, energy_max: 1.1619999\n",
      "energy_min: 0.065, energy_max: 0.742\n",
      "Query execution time: 0.3161430358886719 milliseconds\n"
     ]
    }
   ],
   "source": [
    "# Convert to datetime\n",
    "start = datetime(2012, 6, 1)\n",
    "end = datetime(2013, 6, 1)\n",
    "\n",
    "# Specify query\n",
    "query = {\n",
    "    \"LCLid\": \"MAC000131\",\n",
    "    \"day\": {'$lt': end, '$gte': start}\n",
    "}\n",
    "\n",
    "# Start timer\n",
    "start_time = time.time()\n",
    "\n",
    "# Retrieve all documents\n",
    "result_cursor = collection.find(query, {\"energy_min\": 1, \"energy_max\": 1})\n",
    "\n",
    "# End timer\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate execution time\n",
    "execution_time = (end_time - start_time)*1000\n",
    "\n",
    "# Print values\n",
    "count = 0\n",
    "for document in result_cursor:\n",
    "    energy_min = document.get(\"energy_min\")\n",
    "    energy_max = document.get(\"energy_max\")\n",
    "    print(f\"energy_min: {energy_min}, energy_max: {energy_max}\")\n",
    "    count += 1\n",
    "    if count == 5:\n",
    "        break\n",
    "    \n",
    "# Print execution time\n",
    "print(f\"Query execution time: {execution_time} milliseconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc2c484-0273-4c23-8f21-168a07278a72",
   "metadata": {},
   "source": [
    "## Third Query Workload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "504fe798-6717-4fa8-92ef-dcac0d66df06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "energy_min: 0.064, energy_max: 0.312\n",
      "energy_min: 0.065, energy_max: 0.299\n",
      "energy_min: 0.064, energy_max: 0.7829999999999999\n",
      "energy_min: 0.066, energy_max: 1.1619999\n",
      "energy_min: 0.065, energy_max: 0.742\n",
      "Query execution time: 0.24890899658203125 milliseconds\n"
     ]
    }
   ],
   "source": [
    "# Convert to datetime\n",
    "start = datetime(2012, 6, 1)\n",
    "end = datetime(2013, 6, 1)\n",
    "\n",
    "# Specify query\n",
    "query = {\n",
    "    \"LCLid\": \"MAC000131\",\n",
    "    \"day\": {'$lt': end, '$gte': start}\n",
    "}\n",
    "\n",
    "# Start timer\n",
    "start_time = time.time()\n",
    "\n",
    "# Retrieve all documents\n",
    "result_cursor = collection.find(query, {\"energy_min\": 1, \"energy_max\": 1})\n",
    "\n",
    "# End timer\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate execution time\n",
    "execution_time = (end_time - start_time)*1000\n",
    "\n",
    "# Print values\n",
    "count = 0\n",
    "for document in result_cursor:\n",
    "    energy_min = document.get(\"energy_min\")\n",
    "    energy_max = document.get(\"energy_max\")\n",
    "    print(f\"energy_min: {energy_min}, energy_max: {energy_max}\")\n",
    "    count += 1\n",
    "    if count == 5:\n",
    "        break\n",
    "    \n",
    "# Print execution time\n",
    "print(f\"Query execution time: {execution_time} milliseconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f314be-0743-4fb3-b2e3-408356e2a301",
   "metadata": {},
   "source": [
    "## Overall Query Execution Time for Simple Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "729af279-782a-4c64-914a-78122ca9b8cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Query Execution Time: 0.3 milliseconds\n"
     ]
    }
   ],
   "source": [
    "print(f\"Average Query Execution Time: {((0.33+0.32+0.25)/3)} milliseconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd19285-e9cd-4dec-8fda-97fdb73935bb",
   "metadata": {},
   "source": [
    "# Filter and Aggregation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2155d2-33d1-4a2e-8274-eaa3e7fd1ea7",
   "metadata": {},
   "source": [
    "## First Query Workload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "57d652d3-f343-45ed-b185-fba22989325e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LCLid: MAC000131, Total Sum: 3691.9949997\n",
      "LCLid: MAC000132, Total Sum: 5258.8470011\n",
      "LCLid: MAC000221, Total Sum: 4917.5459997\n",
      "LCLid: MAC000228, Total Sum: 2707.6260003\n",
      "LCLid: MAC000234, Total Sum: 4213.725\n",
      "LCLid: MAC000235, Total Sum: 1528.1550001\n",
      "Query execution time: 8.754968643188477 milliseconds\n"
     ]
    }
   ],
   "source": [
    "# Convert to datetime\n",
    "start = datetime(2012, 6, 1)\n",
    "end = datetime(2013, 6, 2)\n",
    "\n",
    "# Specify query\n",
    "pipeline = [\n",
    "    {\n",
    "        '$match': {\n",
    "            'day': {'$lt': end, '$gte': start}\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        '$group': {\n",
    "            '_id': '$LCLid',\n",
    "            'totalSum': {\n",
    "                '$sum': '$energy_sum'\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        '$sort': {\n",
    "            '_id': 1\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "# Start timer\n",
    "start_time = time.time()\n",
    "\n",
    "# Execute query\n",
    "results = collection.aggregate(pipeline)\n",
    "\n",
    "# End timer\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate eecution time\n",
    "execution_time = (end_time - start_time) * 1000\n",
    "\n",
    "# Print results\n",
    "for result in results:\n",
    "    LCLid = result['_id']\n",
    "    totalSum = result['totalSum']\n",
    "    print(f\"LCLid: {LCLid}, Total Sum: {totalSum}\")\n",
    "\n",
    "# Print query execution time\n",
    "print(f\"Query execution time: {execution_time} milliseconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d654d9-cc31-4e8b-81fe-aa6661f6cc2a",
   "metadata": {},
   "source": [
    "## Second Query Workload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "356e8333-08c7-4b9e-a92b-a848191f9f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LCLid: MAC000131, Total Sum: 3691.9949997\n",
      "LCLid: MAC000132, Total Sum: 5258.8470011\n",
      "LCLid: MAC000221, Total Sum: 4917.5459997\n",
      "LCLid: MAC000228, Total Sum: 2707.6260003\n",
      "LCLid: MAC000234, Total Sum: 4213.725\n",
      "LCLid: MAC000235, Total Sum: 1528.1550001\n",
      "Query execution time: 10.632991790771484 milliseconds\n"
     ]
    }
   ],
   "source": [
    "# Convert to datetime\n",
    "start = datetime(2012, 6, 1)\n",
    "end = datetime(2013, 6, 2)\n",
    "\n",
    "# Specify query\n",
    "pipeline = [\n",
    "    {\n",
    "        '$match': {\n",
    "            'day': {'$lt': end, '$gte': start}\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        '$group': {\n",
    "            '_id': '$LCLid',\n",
    "            'totalSum': {\n",
    "                '$sum': '$energy_sum'\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        '$sort': {\n",
    "            '_id': 1\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "# Start timer\n",
    "start_time = time.time()\n",
    "\n",
    "# Execute query\n",
    "results = collection.aggregate(pipeline)\n",
    "\n",
    "# End timer\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate eecution time\n",
    "execution_time = (end_time - start_time) * 1000\n",
    "\n",
    "# Print results\n",
    "for result in results:\n",
    "    LCLid = result['_id']\n",
    "    totalSum = result['totalSum']\n",
    "    print(f\"LCLid: {LCLid}, Total Sum: {totalSum}\")\n",
    "\n",
    "# Print query execution time\n",
    "print(f\"Query execution time: {execution_time} milliseconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709b6a16-8cea-4c81-9b6b-53c663d5b621",
   "metadata": {},
   "source": [
    "## Third Query Workload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "ca233b9b-b3b8-425b-98e0-412ba601022f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LCLid: MAC000131, Total Sum: 3691.9949997\n",
      "LCLid: MAC000132, Total Sum: 5258.8470011\n",
      "LCLid: MAC000221, Total Sum: 4917.5459997\n",
      "LCLid: MAC000228, Total Sum: 2707.6260003\n",
      "LCLid: MAC000234, Total Sum: 4213.725\n",
      "LCLid: MAC000235, Total Sum: 1528.1550001\n",
      "Query execution time: 9.136199951171875 milliseconds\n"
     ]
    }
   ],
   "source": [
    "# Convert to datetime\n",
    "start = datetime(2012, 6, 1)\n",
    "end = datetime(2013, 6, 2)\n",
    "\n",
    "# Specify query\n",
    "pipeline = [\n",
    "    {\n",
    "        '$match': {\n",
    "            'day': {'$lt': end, '$gte': start}\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        '$group': {\n",
    "            '_id': '$LCLid',\n",
    "            'totalSum': {\n",
    "                '$sum': '$energy_sum'\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        '$sort': {\n",
    "            '_id': 1\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "# Start timer\n",
    "start_time = time.time()\n",
    "\n",
    "# Execute query\n",
    "results = collection.aggregate(pipeline)\n",
    "\n",
    "# End timer\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate eecution time\n",
    "execution_time = (end_time - start_time) * 1000\n",
    "\n",
    "# Print results\n",
    "for result in results:\n",
    "    LCLid = result['_id']\n",
    "    totalSum = result['totalSum']\n",
    "    print(f\"LCLid: {LCLid}, Total Sum: {totalSum}\")\n",
    "\n",
    "# Print query execution time\n",
    "print(f\"Query execution time: {execution_time} milliseconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804257ab-e704-423b-b02f-83ea1b804e9a",
   "metadata": {},
   "source": [
    "## Overall Query Execution Time for Filter and Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "318fe751-aa69-4a65-9ebe-a9c0c970ef42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Query Execution Time: 9.503333333333336 milliseconds\n"
     ]
    }
   ],
   "source": [
    "print(f\"Average Query Execution Time: {((8.75+10.63+9.13)/3)} milliseconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc250ec9-ee4a-4b84-8e32-1c6211877654",
   "metadata": {},
   "source": [
    "# Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "3bb9cf60-2272-43e8-a043-d9475e6d30d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database Names:\n",
      "admin\n",
      "config\n",
      "local\n",
      "test\n",
      "\n",
      "Collection Names:\n",
      "smart-meter-benchmark\n",
      "\n",
      "Index Information:\n",
      "{'_id_': {'v': 2, 'key': [('_id', 1)]}}\n"
     ]
    }
   ],
   "source": [
    "database_names = client.list_database_names()\n",
    "print(\"Database Names:\")\n",
    "for name in database_names:\n",
    "    print(name)\n",
    "\n",
    "collection_names = db.list_collection_names()\n",
    "print(\"\\nCollection Names:\")\n",
    "for name in collection_names:\n",
    "    print(name)\n",
    "\n",
    "index_info = collection.index_information()\n",
    "print(\"\\nIndex Information:\")\n",
    "\n",
    "print(index_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "0b04eb68-976b-40c9-8523-ed8f52a806b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ObjectId: 64a2f7f5a67a64dabfab0b26\n",
      "ObjectId: 64a2f7f5a67a64dabfab0b27\n",
      "ObjectId: 64a2f7f5a67a64dabfab0b28\n",
      "ObjectId: 64a2f7f5a67a64dabfab0b29\n",
      "ObjectId: 64a2f7f5a67a64dabfab0b2a\n"
     ]
    }
   ],
   "source": [
    "# Retrieve all ObjectIDs from the collection\n",
    "object_ids = collection.distinct(\"_id\", {})\n",
    "\n",
    "count = 0\n",
    "for object_id in object_ids:\n",
    "    print(f\"ObjectId: {object_id}\")\n",
    "    count += 1\n",
    "    if count == 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "1585a419-6d99-4a58-87e3-2ecaad9b6fd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace of collection: test.smart-meter-benchmark\n",
      "Total size of collection in bytes: 964458\n",
      "Number of documents: 4871\n",
      "Average size of an object: 198\n",
      "Storage size of collection in bytes: 348160\n"
     ]
    }
   ],
   "source": [
    "# Print some collection statistics\n",
    "command = {\"collStats\": collection.name}\n",
    "stats = db.command(command)\n",
    "\n",
    "print(\"Namespace of collection:\", stats[\"ns\"])\n",
    "print(\"Total size of collection in bytes:\", stats[\"size\"])\n",
    "print(\"Number of documents:\", stats[\"count\"])\n",
    "print(\"Average size of an object:\", stats[\"avgObjSize\"])\n",
    "print(\"Storage size of collection in bytes:\", stats[\"storageSize\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "f66886b4-ce4d-46a1-972e-25880896e3b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ns': 'test.smart-meter-benchmark', 'size': 964458, 'count': 4871, 'avgObjSize': 198, 'numOrphanDocs': 0, 'storageSize': 348160, 'freeStorageSize': 0, 'capped': False, 'wiredTiger': {'metadata': {'formatVersion': 1}, 'creationString': 'access_pattern_hint=none,allocation_size=4KB,app_metadata=(formatVersion=1),assert=(commit_timestamp=none,durable_timestamp=none,read_timestamp=none,write_timestamp=off),block_allocation=best,block_compressor=snappy,cache_resident=false,checksum=on,colgroups=,collator=,columns=,dictionary=0,encryption=(keyid=,name=),exclusive=false,extractor=,format=btree,huffman_key=,huffman_value=,ignore_in_memory_cache_size=false,immutable=false,import=(compare_timestamp=oldest_timestamp,enabled=false,file_metadata=,metadata_file=,repair=false),internal_item_max=0,internal_key_max=0,internal_key_truncate=true,internal_page_max=4KB,key_format=q,key_gap=10,leaf_item_max=0,leaf_key_max=0,leaf_page_max=32KB,leaf_value_max=64MB,log=(enabled=true),lsm=(auto_throttle=true,bloom=true,bloom_bit_count=16,bloom_config=,bloom_hash_count=8,bloom_oldest=false,chunk_count_limit=0,chunk_max=5GB,chunk_size=10MB,merge_custom=(prefix=,start_generation=0,suffix=),merge_max=15,merge_min=0),memory_page_image_max=0,memory_page_max=10m,os_cache_dirty_max=0,os_cache_max=0,prefix_compression=false,prefix_compression_min=4,readonly=false,source=,split_deepen_min_child=0,split_deepen_per_child=0,split_pct=90,tiered_object=false,tiered_storage=(auth_token=,bucket=,bucket_prefix=,cache_directory=,local_retention=300,name=,object_target_size=0),type=file,value_format=u,verbose=[],write_timestamp_usage=none', 'type': 'file', 'uri': 'statistics:table:collection-14-520139836481677603', 'LSM': {'bloom filter false positives': 0, 'bloom filter hits': 0, 'bloom filter misses': 0, 'bloom filter pages evicted from cache': 0, 'bloom filter pages read into cache': 0, 'bloom filters in the LSM tree': 0, 'chunks in the LSM tree': 0, 'highest merge generation in the LSM tree': 0, 'queries that could have benefited from a Bloom filter that did not exist': 0, 'sleep for LSM checkpoint throttle': 0, 'sleep for LSM merge throttle': 0, 'total size of bloom filters': 0}, 'autocommit': {'retries for readonly operations': 0, 'retries for update operations': 0}, 'block-manager': {'allocations requiring file extension': 12, 'blocks allocated': 12, 'blocks freed': 0, 'checkpoint size': 331776, 'file allocation unit size': 4096, 'file bytes available for reuse': 0, 'file magic number': 120897, 'file major version number': 1, 'file size in bytes': 348160, 'minor version number': 0}, 'btree': {'btree checkpoint generation': 1086, 'btree clean tree checkpoint expiration time': 9223372036854775807, 'btree compact pages reviewed': 0, 'btree compact pages rewritten': 0, 'btree compact pages skipped': 0, 'btree skipped by compaction as process would not reduce size': 0, 'column-store fixed-size leaf pages': 0, 'column-store fixed-size time windows': 0, 'column-store internal pages': 0, 'column-store variable-size RLE encoded values': 0, 'column-store variable-size deleted values': 0, 'column-store variable-size leaf pages': 0, 'fixed-record size': 0, 'maximum internal page size': 4096, 'maximum leaf page key size': 2867, 'maximum leaf page size': 32768, 'maximum leaf page value size': 67108864, 'maximum tree depth': 3, 'number of key/value pairs': 0, 'overflow pages': 0, 'row-store empty values': 0, 'row-store internal pages': 0, 'row-store leaf pages': 0}, 'cache': {'bytes currently in the cache': 1498435, 'bytes dirty in the cache cumulative': 934, 'bytes read into cache': 0, 'bytes written from cache': 994139, 'checkpoint blocked page eviction': 0, 'checkpoint of history store file blocked non-history store page eviction': 0, 'data source pages selected for eviction unable to be evicted': 0, 'eviction gave up due to detecting an out of order on disk value behind the last update on the chain': 0, 'eviction gave up due to detecting an out of order tombstone ahead of the selected on disk update': 0, 'eviction gave up due to detecting an out of order tombstone ahead of the selected on disk update after validating the update chain': 0, 'eviction gave up due to detecting out of order timestamps on the update chain after the selected on disk update': 0, 'eviction gave up due to needing to remove a record from the history store but checkpoint is running': 0, 'eviction walk passes of a file': 0, 'eviction walk target pages histogram - 0-9': 0, 'eviction walk target pages histogram - 10-31': 0, 'eviction walk target pages histogram - 128 and higher': 0, 'eviction walk target pages histogram - 32-63': 0, 'eviction walk target pages histogram - 64-128': 0, 'eviction walk target pages reduced due to history store cache pressure': 0, 'eviction walks abandoned': 0, 'eviction walks gave up because they restarted their walk twice': 0, 'eviction walks gave up because they saw too many pages and found no candidates': 0, 'eviction walks gave up because they saw too many pages and found too few candidates': 0, 'eviction walks reached end of tree': 0, 'eviction walks restarted': 0, 'eviction walks started from root of tree': 0, 'eviction walks started from saved location in tree': 0, 'hazard pointer blocked page eviction': 0, 'history store table insert calls': 0, 'history store table insert calls that returned restart': 0, 'history store table out-of-order resolved updates that lose their durable timestamp': 0, 'history store table out-of-order updates that were fixed up by reinserting with the fixed timestamp': 0, 'history store table reads': 0, 'history store table reads missed': 0, 'history store table reads requiring squashed modifies': 0, 'history store table truncation by rollback to stable to remove an unstable update': 0, 'history store table truncation by rollback to stable to remove an update': 0, 'history store table truncation to remove an update': 0, 'history store table truncation to remove range of updates due to key being removed from the data page during reconciliation': 0, 'history store table truncation to remove range of updates due to out-of-order timestamp update on data page': 0, 'history store table writes requiring squashed modifies': 0, 'in-memory page passed criteria to be split': 0, 'in-memory page splits': 0, 'internal pages evicted': 0, 'internal pages split during eviction': 0, 'leaf pages split during eviction': 0, 'modified pages evicted': 0, 'overflow pages read into cache': 0, 'page split during eviction deepened the tree': 0, 'page written requiring history store records': 0, 'pages read into cache': 0, 'pages read into cache after truncate': 1, 'pages read into cache after truncate in prepare state': 0, 'pages requested from the cache': 4985, 'pages seen by eviction walk': 0, 'pages written from cache': 10, 'pages written requiring in-memory restoration': 0, 'the number of times full update inserted to history store': 0, 'the number of times reverse modify inserted to history store': 0, 'tracked dirty bytes in the cache': 0, 'unmodified pages evicted': 0}, 'cache_walk': {'Average difference between current eviction generation when the page was last considered': 0, 'Average on-disk page image size seen': 0, 'Average time in cache for pages that have been visited by the eviction server': 0, 'Average time in cache for pages that have not been visited by the eviction server': 0, 'Clean pages currently in cache': 0, 'Current eviction generation': 0, 'Dirty pages currently in cache': 0, 'Entries in the root page': 0, 'Internal pages currently in cache': 0, 'Leaf pages currently in cache': 0, 'Maximum difference between current eviction generation when the page was last considered': 0, 'Maximum page size seen': 0, 'Minimum on-disk page image size seen': 0, 'Number of pages never visited by eviction server': 0, 'On-disk page image sizes smaller than a single allocation unit': 0, 'Pages created in memory and never written': 0, 'Pages currently queued for eviction': 0, 'Pages that could not be queued for eviction': 0, 'Refs skipped during cache traversal': 0, 'Size of the root page': 0, 'Total number of pages currently in cache': 0}, 'checkpoint-cleanup': {'pages added for eviction': 0, 'pages removed': 0, 'pages skipped during tree walk': 0, 'pages visited': 1}, 'compression': {'compressed page maximum internal page size prior to compression': 4096, 'compressed page maximum leaf page size prior to compression ': 111416, 'compressed pages read': 0, 'compressed pages written': 9, 'number of blocks with compress ratio greater than 64': 0, 'number of blocks with compress ratio smaller than 16': 0, 'number of blocks with compress ratio smaller than 2': 0, 'number of blocks with compress ratio smaller than 32': 0, 'number of blocks with compress ratio smaller than 4': 0, 'number of blocks with compress ratio smaller than 64': 0, 'number of blocks with compress ratio smaller than 8': 0, 'page written failed to compress': 0, 'page written was too small to compress': 1}, 'cursor': {'Total number of entries skipped by cursor next calls': 0, 'Total number of entries skipped by cursor prev calls': 0, 'Total number of entries skipped to position the history store cursor': 0, 'Total number of times a search near has exited due to prefix config': 0, 'bulk loaded cursor insert calls': 0, 'cache cursors reuse count': 32, 'close calls that result in cache': 34, 'create calls': 3, 'cursor next calls that skip due to a globally visible history store tombstone': 0, 'cursor next calls that skip greater than or equal to 100 entries': 0, 'cursor next calls that skip less than 100 entries': 107286, 'cursor prev calls that skip due to a globally visible history store tombstone': 0, 'cursor prev calls that skip greater than or equal to 100 entries': 0, 'cursor prev calls that skip less than 100 entries': 1, 'insert calls': 4871, 'insert key and value bytes': 974137, 'modify': 0, 'modify key and value bytes affected': 0, 'modify value bytes modified': 0, 'next calls': 107286, 'open cursor count': 0, 'operation restarted': 0, 'prev calls': 1, 'remove calls': 0, 'remove key bytes removed': 0, 'reserve calls': 0, 'reset calls': 168, 'search calls': 0, 'search history store calls': 0, 'search near calls': 90, 'truncate calls': 0, 'update calls': 0, 'update key and value bytes': 0, 'update value size change': 0}, 'reconciliation': {'approximate byte size of timestamps in pages written': 0, 'approximate byte size of transaction IDs in pages written': 0, 'dictionary matches': 0, 'fast-path pages deleted': 0, 'internal page key bytes discarded using suffix compression': 16, 'internal page multi-block writes': 0, 'leaf page key bytes discarded using prefix compression': 0, 'leaf page multi-block writes': 1, 'leaf-page overflow keys': 0, 'maximum blocks required for a page': 1, 'overflow values written': 0, 'page checksum matches': 0, 'page reconciliation calls': 2, 'page reconciliation calls for eviction': 0, 'pages deleted': 0, 'pages written including an aggregated newest start durable timestamp ': 0, 'pages written including an aggregated newest stop durable timestamp ': 0, 'pages written including an aggregated newest stop timestamp ': 0, 'pages written including an aggregated newest stop transaction ID': 0, 'pages written including an aggregated newest transaction ID ': 0, 'pages written including an aggregated oldest start timestamp ': 0, 'pages written including an aggregated prepare': 0, 'pages written including at least one prepare': 0, 'pages written including at least one start durable timestamp': 0, 'pages written including at least one start timestamp': 0, 'pages written including at least one start transaction ID': 0, 'pages written including at least one stop durable timestamp': 0, 'pages written including at least one stop timestamp': 0, 'pages written including at least one stop transaction ID': 0, 'records written including a prepare': 0, 'records written including a start durable timestamp': 0, 'records written including a start timestamp': 0, 'records written including a start transaction ID': 0, 'records written including a stop durable timestamp': 0, 'records written including a stop timestamp': 0, 'records written including a stop transaction ID': 0}, 'session': {'object compaction': 0, 'tiered operations dequeued and processed': 0, 'tiered operations scheduled': 0, 'tiered storage local retention time (secs)': 0}, 'transaction': {'race to read prepared update retry': 0, 'rollback to stable history store records with stop timestamps older than newer records': 0, 'rollback to stable inconsistent checkpoint': 0, 'rollback to stable keys removed': 0, 'rollback to stable keys restored': 0, 'rollback to stable restored tombstones from history store': 0, 'rollback to stable restored updates from history store': 0, 'rollback to stable skipping delete rle': 0, 'rollback to stable skipping stable rle': 0, 'rollback to stable sweeping history store keys': 0, 'rollback to stable updates removed from history store': 0, 'transaction checkpoints due to obsolete pages': 0, 'update conflicts': 0}}, 'nindexes': 1, 'indexDetails': {'_id_': {'metadata': {'formatVersion': 8}, 'creationString': 'access_pattern_hint=none,allocation_size=4KB,app_metadata=(formatVersion=8),assert=(commit_timestamp=none,durable_timestamp=none,read_timestamp=none,write_timestamp=off),block_allocation=best,block_compressor=,cache_resident=false,checksum=on,colgroups=,collator=,columns=,dictionary=0,encryption=(keyid=,name=),exclusive=false,extractor=,format=btree,huffman_key=,huffman_value=,ignore_in_memory_cache_size=false,immutable=false,import=(compare_timestamp=oldest_timestamp,enabled=false,file_metadata=,metadata_file=,repair=false),internal_item_max=0,internal_key_max=0,internal_key_truncate=true,internal_page_max=16k,key_format=u,key_gap=10,leaf_item_max=0,leaf_key_max=0,leaf_page_max=16k,leaf_value_max=0,log=(enabled=true),lsm=(auto_throttle=true,bloom=true,bloom_bit_count=16,bloom_config=,bloom_hash_count=8,bloom_oldest=false,chunk_count_limit=0,chunk_max=5GB,chunk_size=10MB,merge_custom=(prefix=,start_generation=0,suffix=),merge_max=15,merge_min=0),memory_page_image_max=0,memory_page_max=5MB,os_cache_dirty_max=0,os_cache_max=0,prefix_compression=true,prefix_compression_min=4,readonly=false,source=,split_deepen_min_child=0,split_deepen_per_child=0,split_pct=90,tiered_object=false,tiered_storage=(auth_token=,bucket=,bucket_prefix=,cache_directory=,local_retention=300,name=,object_target_size=0),type=file,value_format=u,verbose=[],write_timestamp_usage=none', 'type': 'file', 'uri': 'statistics:table:index-15-520139836481677603', 'LSM': {'bloom filter false positives': 0, 'bloom filter hits': 0, 'bloom filter misses': 0, 'bloom filter pages evicted from cache': 0, 'bloom filter pages read into cache': 0, 'bloom filters in the LSM tree': 0, 'chunks in the LSM tree': 0, 'highest merge generation in the LSM tree': 0, 'queries that could have benefited from a Bloom filter that did not exist': 0, 'sleep for LSM checkpoint throttle': 0, 'sleep for LSM merge throttle': 0, 'total size of bloom filters': 0}, 'autocommit': {'retries for readonly operations': 0, 'retries for update operations': 0}, 'block-manager': {'allocations requiring file extension': 6, 'blocks allocated': 6, 'blocks freed': 0, 'checkpoint size': 49152, 'file allocation unit size': 4096, 'file bytes available for reuse': 0, 'file magic number': 120897, 'file major version number': 1, 'file size in bytes': 65536, 'minor version number': 0}, 'btree': {'btree checkpoint generation': 1086, 'btree clean tree checkpoint expiration time': 9223372036854775807, 'btree compact pages reviewed': 0, 'btree compact pages rewritten': 0, 'btree compact pages skipped': 0, 'btree skipped by compaction as process would not reduce size': 0, 'column-store fixed-size leaf pages': 0, 'column-store fixed-size time windows': 0, 'column-store internal pages': 0, 'column-store variable-size RLE encoded values': 0, 'column-store variable-size deleted values': 0, 'column-store variable-size leaf pages': 0, 'fixed-record size': 0, 'maximum internal page size': 16384, 'maximum leaf page key size': 1474, 'maximum leaf page size': 16384, 'maximum leaf page value size': 7372, 'maximum tree depth': 3, 'number of key/value pairs': 0, 'overflow pages': 0, 'row-store empty values': 0, 'row-store internal pages': 0, 'row-store leaf pages': 0}, 'cache': {'bytes currently in the cache': 551736, 'bytes dirty in the cache cumulative': 934, 'bytes read into cache': 0, 'bytes written from cache': 42110, 'checkpoint blocked page eviction': 0, 'checkpoint of history store file blocked non-history store page eviction': 0, 'data source pages selected for eviction unable to be evicted': 0, 'eviction gave up due to detecting an out of order on disk value behind the last update on the chain': 0, 'eviction gave up due to detecting an out of order tombstone ahead of the selected on disk update': 0, 'eviction gave up due to detecting an out of order tombstone ahead of the selected on disk update after validating the update chain': 0, 'eviction gave up due to detecting out of order timestamps on the update chain after the selected on disk update': 0, 'eviction gave up due to needing to remove a record from the history store but checkpoint is running': 0, 'eviction walk passes of a file': 0, 'eviction walk target pages histogram - 0-9': 0, 'eviction walk target pages histogram - 10-31': 0, 'eviction walk target pages histogram - 128 and higher': 0, 'eviction walk target pages histogram - 32-63': 0, 'eviction walk target pages histogram - 64-128': 0, 'eviction walk target pages reduced due to history store cache pressure': 0, 'eviction walks abandoned': 0, 'eviction walks gave up because they restarted their walk twice': 0, 'eviction walks gave up because they saw too many pages and found no candidates': 0, 'eviction walks gave up because they saw too many pages and found too few candidates': 0, 'eviction walks reached end of tree': 0, 'eviction walks restarted': 0, 'eviction walks started from root of tree': 0, 'eviction walks started from saved location in tree': 0, 'hazard pointer blocked page eviction': 0, 'history store table insert calls': 0, 'history store table insert calls that returned restart': 0, 'history store table out-of-order resolved updates that lose their durable timestamp': 0, 'history store table out-of-order updates that were fixed up by reinserting with the fixed timestamp': 0, 'history store table reads': 0, 'history store table reads missed': 0, 'history store table reads requiring squashed modifies': 0, 'history store table truncation by rollback to stable to remove an unstable update': 0, 'history store table truncation by rollback to stable to remove an update': 0, 'history store table truncation to remove an update': 0, 'history store table truncation to remove range of updates due to key being removed from the data page during reconciliation': 0, 'history store table truncation to remove range of updates due to out-of-order timestamp update on data page': 0, 'history store table writes requiring squashed modifies': 0, 'in-memory page passed criteria to be split': 0, 'in-memory page splits': 0, 'internal pages evicted': 0, 'internal pages split during eviction': 0, 'leaf pages split during eviction': 0, 'modified pages evicted': 0, 'overflow pages read into cache': 0, 'page split during eviction deepened the tree': 0, 'page written requiring history store records': 0, 'pages read into cache': 0, 'pages read into cache after truncate': 1, 'pages read into cache after truncate in prepare state': 0, 'pages requested from the cache': 34104, 'pages seen by eviction walk': 0, 'pages written from cache': 4, 'pages written requiring in-memory restoration': 0, 'the number of times full update inserted to history store': 0, 'the number of times reverse modify inserted to history store': 0, 'tracked dirty bytes in the cache': 0, 'unmodified pages evicted': 0}, 'cache_walk': {'Average difference between current eviction generation when the page was last considered': 0, 'Average on-disk page image size seen': 0, 'Average time in cache for pages that have been visited by the eviction server': 0, 'Average time in cache for pages that have not been visited by the eviction server': 0, 'Clean pages currently in cache': 0, 'Current eviction generation': 0, 'Dirty pages currently in cache': 0, 'Entries in the root page': 0, 'Internal pages currently in cache': 0, 'Leaf pages currently in cache': 0, 'Maximum difference between current eviction generation when the page was last considered': 0, 'Maximum page size seen': 0, 'Minimum on-disk page image size seen': 0, 'Number of pages never visited by eviction server': 0, 'On-disk page image sizes smaller than a single allocation unit': 0, 'Pages created in memory and never written': 0, 'Pages currently queued for eviction': 0, 'Pages that could not be queued for eviction': 0, 'Refs skipped during cache traversal': 0, 'Size of the root page': 0, 'Total number of pages currently in cache': 0}, 'checkpoint-cleanup': {'pages added for eviction': 0, 'pages removed': 0, 'pages skipped during tree walk': 0, 'pages visited': 1}, 'compression': {'compressed page maximum internal page size prior to compression': 16384, 'compressed page maximum leaf page size prior to compression ': 16384, 'compressed pages read': 0, 'compressed pages written': 0, 'number of blocks with compress ratio greater than 64': 0, 'number of blocks with compress ratio smaller than 16': 0, 'number of blocks with compress ratio smaller than 2': 0, 'number of blocks with compress ratio smaller than 32': 0, 'number of blocks with compress ratio smaller than 4': 0, 'number of blocks with compress ratio smaller than 64': 0, 'number of blocks with compress ratio smaller than 8': 0, 'page written failed to compress': 0, 'page written was too small to compress': 0}, 'cursor': {'Total number of entries skipped by cursor next calls': 0, 'Total number of entries skipped by cursor prev calls': 0, 'Total number of entries skipped to position the history store cursor': 0, 'Total number of times a search near has exited due to prefix config': 0, 'bulk loaded cursor insert calls': 0, 'cache cursors reuse count': 6, 'close calls that result in cache': 7, 'create calls': 1, 'cursor next calls that skip due to a globally visible history store tombstone': 0, 'cursor next calls that skip greater than or equal to 100 entries': 0, 'cursor next calls that skip less than 100 entries': 6, 'cursor prev calls that skip due to a globally visible history store tombstone': 0, 'cursor prev calls that skip greater than or equal to 100 entries': 0, 'cursor prev calls that skip less than 100 entries': 0, 'insert calls': 4871, 'insert key and value bytes': 81784, 'modify': 0, 'modify key and value bytes affected': 0, 'modify value bytes modified': 0, 'next calls': 6, 'open cursor count': 0, 'operation restarted': 0, 'prev calls': 0, 'remove calls': 0, 'remove key bytes removed': 0, 'reserve calls': 0, 'reset calls': 4910, 'search calls': 0, 'search history store calls': 0, 'search near calls': 29232, 'truncate calls': 0, 'update calls': 0, 'update key and value bytes': 0, 'update value size change': 0}, 'reconciliation': {'approximate byte size of timestamps in pages written': 0, 'approximate byte size of transaction IDs in pages written': 0, 'dictionary matches': 0, 'fast-path pages deleted': 0, 'internal page key bytes discarded using suffix compression': 10, 'internal page multi-block writes': 0, 'leaf page key bytes discarded using prefix compression': 54556, 'leaf page multi-block writes': 1, 'leaf-page overflow keys': 0, 'maximum blocks required for a page': 1, 'overflow values written': 0, 'page checksum matches': 0, 'page reconciliation calls': 2, 'page reconciliation calls for eviction': 0, 'pages deleted': 0, 'pages written including an aggregated newest start durable timestamp ': 0, 'pages written including an aggregated newest stop durable timestamp ': 0, 'pages written including an aggregated newest stop timestamp ': 0, 'pages written including an aggregated newest stop transaction ID': 0, 'pages written including an aggregated newest transaction ID ': 0, 'pages written including an aggregated oldest start timestamp ': 0, 'pages written including an aggregated prepare': 0, 'pages written including at least one prepare': 0, 'pages written including at least one start durable timestamp': 0, 'pages written including at least one start timestamp': 0, 'pages written including at least one start transaction ID': 0, 'pages written including at least one stop durable timestamp': 0, 'pages written including at least one stop timestamp': 0, 'pages written including at least one stop transaction ID': 0, 'records written including a prepare': 0, 'records written including a start durable timestamp': 0, 'records written including a start timestamp': 0, 'records written including a start transaction ID': 0, 'records written including a stop durable timestamp': 0, 'records written including a stop timestamp': 0, 'records written including a stop transaction ID': 0}, 'session': {'object compaction': 0, 'tiered operations dequeued and processed': 0, 'tiered operations scheduled': 0, 'tiered storage local retention time (secs)': 0}, 'transaction': {'race to read prepared update retry': 0, 'rollback to stable history store records with stop timestamps older than newer records': 0, 'rollback to stable inconsistent checkpoint': 0, 'rollback to stable keys removed': 0, 'rollback to stable keys restored': 0, 'rollback to stable restored tombstones from history store': 0, 'rollback to stable restored updates from history store': 0, 'rollback to stable skipping delete rle': 0, 'rollback to stable skipping stable rle': 0, 'rollback to stable sweeping history store keys': 0, 'rollback to stable updates removed from history store': 0, 'transaction checkpoints due to obsolete pages': 0, 'update conflicts': 0}}}, 'indexBuilds': [], 'totalIndexSize': 65536, 'totalSize': 413696, 'indexSizes': {'_id_': 65536}, 'scaleFactor': 1, 'ok': 1.0}\n"
     ]
    }
   ],
   "source": [
    "# Print all the available statistics\n",
    "print(stats)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
